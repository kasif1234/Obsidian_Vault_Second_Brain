- Problem framing exposure  
    Turning a messy idea into a clear research question, hypothesis, and success metric.
    
- Literature scanning exposure  
    Reading papers fast, extracting what matters, and building a “what is missing” gap statement.
    
- Data and ground truth exposure  
    Collecting, cleaning, labeling, spotting leakage or bias, and knowing when the data is lying to you.
    
- Baseline first exposure  
    Reproducing a baseline from a paper or repo, matching numbers, and explaining any mismatch.
    
- Experiment design exposure  
    Ablations, controls, fair comparisons, and knowing which variable you are actually changing.
    
- Debugging under uncertainty exposure  
    When results fail, you systematically isolate the cause (data, code, metric, model, randomness).
    
- Reproducibility and MLOps exposure  
    Seeds, configs, versioning, logging runs, saving checkpoints, writing “how to rerun” steps.
    
- Evaluation and metrics exposure  
    Picking the right metric, interpreting it, and analyzing failure cases with examples.
    
- Insight to narrative exposure  
    Converting results into a story: claim → evidence → limitation → next step. Paper style.
    
- Writing and communication exposure  
    Weekly updates, clear figures, clean tables, concise methods, and “decision-ready” summaries.
    
- Collaboration exposure  
    Working with seniors, taking feedback fast, aligning on priorities, and reducing their mental load.
    
- Shipping exposure  
    Submitting a workshop, poster, paper, or internal report. Deadlines teach seriousness.

![[RA successs.pdf]]